# Server Benchmark Configuration

# Global benchmark settings
benchmark:
  local_results_dir: "results"           # Local directory to store results
  huggingface_cache_dir: "/hf_models"    # Directory on remote servers to store HuggingFace models and cache

# Benchmark parameters (required)
benchmark_params:
  max_concurrency: 2048      # Maximum concurrent requests
  num_prompts: 2048          # Number of prompts to benchmark
  random_input_len: 1000     # Random input length for benchmark
  random_output_len: 1000    # Random output length for benchmark

# GPU Pricing ($ per hour per GPU)
pricing:
  rtx4090: 0.39     # RTX 4090 price per GPU per hour
  rtx5090: 0.65     # RTX 5090 price per GPU per hour
  pro6000: 1.29     # RTX 6000 / Pro 6000 price per GPU per hour

# Define servers with their models to benchmark
servers:
#  - name: "rtx4090_x_1"
#    address: "riftuser@142.214.185.238"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
#        extra_args: "--max-model-len 8192"

#  - name: "rtx4090_x_2"
#    address: "riftuser@142.214.185.151"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
#        num_instances: 2
#        extra_args: "--max-model-len 8192"
#      - name: "ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4"
#        pipeline_parallel_size: 2
#        extra_args: "--max-model-len 8192 --kv-cache-dtype fp8"

#  - name: "rtx4090_x_4"
#    address: "riftuser@142.214.185.239"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
#        num_instances: 4
#        extra_args: "--max-model-len 8192"
#      - name: "ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4"
#        pipeline_parallel_size: 2
#        num_instances: 2
#        extra_args: "--max-model-len 8192 --kv-cache-dtype fp8"
#      - name: "cpatonn/GLM-4.5-Air-AWQ-4bit"
#        pipeline_parallel_size: 4
#        extra_args: "--tool-call-parser glm45 --reasoning-parser glm45 --max-model-len 8192 --enable-expert-parallel --kv-cache-dtype fp8"

#  - name: "rtx5090_x_1"
#    address: "riftuser@217.138.104.165"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
#        extra_args: "--max-model-len 8192"

#  - name: "rtx5090_x_2"
#    address: "riftuser@217.138.104.153"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
#        num_instances: 2
#        extra_args: "--max-model-len 8192"
#      - name: "ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4"
#        pipeline_parallel_size: 2
#        extra_args: "--max-model-len 8192 --kv-cache-dtype fp8"

#  - name: "rtx5090_x_4"
#    address: "riftuser@217.138.104.164"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
#        num_instances: 4
#        extra_args: "--max-model-len 8192"
#      - name: "ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4"
#        pipeline_parallel_size: 2
#        num_instances: 2
#        extra_args: "--max-model-len 8192 --kv-cache-dtype fp8"
#      - name: "cpatonn/GLM-4.5-Air-AWQ-4bit"
#        tensor_parallel_size: 4
#        extra_args: "--tool-call-parser glm45 --reasoning-parser glm45 --max-model-len 8192 --max-num-seqs 128 --enable-expert-parallel --kv-cache-dtype fp8"

#  - name: "pro6000_x_1"
#    address: "riftuser@74.81.65.42"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
#        extra_args: "--max-model-len 8192"
#      - name: "ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4"
#        extra_args: "--max-model-len 8192 --kv-cache-dtype fp8"
#      - name: "cpatonn/GLM-4.5-Air-AWQ-4bit"
#        extra_args: "--tool-call-parser glm45 --reasoning-parser glm45 --max-model-len 8192 --max-num-seqs 256 --enable-expert-parallel --kv-cache-dtype fp8"

#  - name: "l40s_x_2"
#    address: "riftuser@91.201.219.165"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
#        num_instances: 2
#        extra_args: "--max-model-len 8192"
#      - name: "ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4"
#        num_instances: 2
#        extra_args: "--max-model-len 8192 --kv-cache-dtype fp8"
#      - name: "cpatonn/GLM-4.5-Air-AWQ-4bit"
#        pipeline_parallel_size: 2
#        extra_args: "--tool-call-parser glm45 --reasoning-parser glm45 --max-model-len 8192 --enable-expert-parallel --kv-cache-dtype fp8"

#  - name: "h200_x_1"
#    address: "riftuser@91.201.219.161"
#    ssh_key: "~/.ssh/id_ed25519"
#    port: 22
#    models:
#      - name: "cpatonn/GLM-4.5-Air-AWQ-4bit"
#        extra_args: "--tool-call-parser glm45 --reasoning-parser glm45 --max-model-len 8192 --max-num-seqs 256 --enable-expert-parallel --kv-cache-dtype fp8"

#  - name: "h200_x_8"
#    address: "hc-h200-1"
#    ssh_key: "~/.ssh/hc_h200_1"
#    port: 22
#    models:
#      - name: "cpatonn/GLM-4.5-Air-AWQ-4bit"
#        num_instances: 8
#        extra_args: "--tool-call-parser glm45 --reasoning-parser glm45 --max-model-len 8192 --max-num-seqs 256 --enable-expert-parallel --kv-cache-dtype fp8"
#      - name: "QuantTrio/Qwen3-Coder-480B-A35B-Instruct-AWQ"
#        tensor_parallel_size: 4
#        num_instances: 2
#        extra_args: "--max-num-seqs 512 --max-model-len 8192 --enable-expert-parallel"
#      - name: "zai-org/GLM-4.6"
#        tensor_parallel_size: 8
#        extra_args: "--tool-call-parser glm45 --reasoning-parser glm45 --max-num-seqs 512 --max-model-len 8192"

# Results will be saved with flat structure using prefixes:
#   {local_results_dir}/{server_name}_{model_name}_system_info.txt
#   {local_results_dir}/{server_name}_{model_name}_hf_download.txt
#   {local_results_dir}/{server_name}_{model_name}_vllm_benchmark.txt
#   {local_results_dir}/{server_name}_{model_name}_yabs.txt
