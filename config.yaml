# Server Benchmark Configuration

# Global benchmark settings
benchmark:
  local_results_dir: "results"           # Local directory to store results

# Optional: Override benchmark parameters
# benchmark_params:
#   max_concurrency: 200
#   num_prompts: 1000
#   random_input_len: 1000
#   random_output_len: 1000

# Define servers with their models to benchmark
servers:
  - name: "rtx4090_x_1"
    address: "riftuser@142.214.185.238"
    ssh_key: "~/.ssh/id_ed25519"
    port: 22
    models:
      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"  # 4-bit quantized, similar to Q4_K_M
        tensor_parallel_size: 1

  - name: "rtx4090_x_2"
    address: "riftuser@142.214.185.150"
    ssh_key: "~/.ssh/id_ed25519"
    port: 22
    models:
      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
        tensor_parallel_size: 1  # Each instance uses 1 GPU
        num_instances: 2         # Run 2 instances for 2x throughput
      - name: "Qwen/Qwen2.5-72B-Instruct-AWQ"
        tensor_parallel_size: 2  # 72B model needs multi-GPU

  - name: "rtx4090_x_4"
    address: "riftuser@142.214.185.230"
    ssh_key: "~/.ssh/id_ed25519"
    port: 22
    models:
      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
        tensor_parallel_size: 1  # Each instance uses 1 GPU
        num_instances: 4         # Run 4 instances for 4x throughput
      - name: "Qwen/Qwen2.5-72B-Instruct-AWQ"
        tensor_parallel_size: 2  # 72B model uses 2 GPUs per instance
        num_instances: 2         # Run 2 instances (GPU 0-1, GPU 2-3)
      - name: "QuantTrio/GLM-4.5-Air-AWQ-FP16Mix"
        tensor_parallel_size: 4  # 106B model uses 4 GPUs
        extra_args: "--enable-expert-parallel --swap-space 16 --max-num-seqs 512 --max-model-len 32768"

  - name: "rtx5090_x_1"
    address: "riftuser@217.138.104.159"
    ssh_key: "~/.ssh/id_ed25519"
    port: 22
    models:
      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
        tensor_parallel_size: 1

  - name: "rtx5090_x_2"
    address: "riftuser@217.138.104.153"
    ssh_key: "~/.ssh/id_ed25519"
    port: 22
    models:
      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
        tensor_parallel_size: 1
        num_instances: 2
      - name: "Qwen/Qwen2.5-72B-Instruct-AWQ"
        tensor_parallel_size: 2

  - name: "rtx5090_x_4"
    address: "riftuser@217.138.104.158"
    ssh_key: "~/.ssh/id_ed25519"
    port: 22
    models:
      - name: "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ"
        tensor_parallel_size: 1
        num_instances: 4
      - name: "Qwen/Qwen2.5-72B-Instruct-AWQ"
        tensor_parallel_size: 2
        num_instances: 2
      - name: "QuantTrio/GLM-4.5-Air-AWQ-FP16Mix"
        tensor_parallel_size: 4
        extra_args: "--enable-expert-parallel --swap-space 16 --max-num-seqs 512 --max-model-len 32768 --max-seq-len-to-capture 32768"


# Results will be saved with flat structure using prefixes:
#   {local_results_dir}/{server_name}_{model_name}_system_info.txt
#   {local_results_dir}/{server_name}_{model_name}_hf_download.txt
#   {local_results_dir}/{server_name}_{model_name}_vllm_benchmark.txt
#   {local_results_dir}/{server_name}_{model_name}_yabs.txt
